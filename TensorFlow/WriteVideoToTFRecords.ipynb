{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "from tensorflow.python.platform import gfile\n",
    "from tensorflow.python.platform import flags\n",
    "from tensorflow.python.platform import app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_string('f', '', 'kernel')\n",
    "flags.DEFINE_integer('n_videos_in_record', 10,\n",
    "                     'Number of videos stored in one single tfrecord file')\n",
    "flags.DEFINE_string('image_color_depth', \"uint8\",\n",
    "                    'Color depth as string for the images stored in the tfrecord files. '\n",
    "                    'Has to correspond to the source video color depth. '\n",
    "                    'Specified as dtype (e.g. uint8 or uint16)')\n",
    "flags.DEFINE_boolean('optical_flow', True,\n",
    "                     'Indicates whether optical flow shall be computed and added as fourth '\n",
    "                     'channel.')\n",
    "flags.DEFINE_integer('width_video', 1280, 'the width of the videos in pixels')\n",
    "flags.DEFINE_integer('height_video', 720, 'the height of the videos in pixels')\n",
    "flags.DEFINE_integer('n_frames_per_video', 5,\n",
    "                     'specifies the number of frames to be taken from each video')\n",
    "flags.DEFINE_integer('n_channels', 4,\n",
    "                     'specifies the number of channels the videos have')\n",
    "flags.DEFINE_string('video_filenames', None,\n",
    "                    'specifies the video file names as a list in the case the video paths shall not be determined by the '\n",
    "                    'script')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def get_chunks(l, n):\n",
    "    \"\"\"Split list to chunks\"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_capture_and_frame_count(path):\n",
    "    assert os.path.isfile(path), \"Couldn't find video file:\" + path + \". Skipping video.\"\n",
    "    cap = None\n",
    "    if path:\n",
    "        cap = cv2.VideoCapture(path)\n",
    "    assert cap is not None, \"Couldn't load video capture:\" + path + \". Skipping video.\"\n",
    "      # compute meta data of video\n",
    "    if hasattr(cv2, 'cv'):\n",
    "        frame_count = int(cap.get(cv2.cv.CAP_PROP_FRAME_COUNT))\n",
    "    else:\n",
    "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    return cap, frame_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_frame(cap):\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        return None\n",
    "    return np.asarray(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dense_optical_flow(prev_image, current_image):\n",
    "\n",
    "    old_shape = current_image.shape\n",
    "    prev_image_gray = cv2.cvtColor(prev_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    current_image_gray = cv2.cvtColor(current_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    assert current_image.shape == old_shape\n",
    "    hsv = np.zeros_like(prev_image)\n",
    "    hsv[..., 1] = 255\n",
    "    flow = None\n",
    "    flow = cv2.calcOpticalFlowFarneback(prev=prev_image_gray,\n",
    "                                  next=current_image_gray, flow=flow,\n",
    "                                  pyr_scale=0.8, levels=15, winsize=5,\n",
    "                                  iterations=10, poly_n=5, poly_sigma=0,\n",
    "                                  flags=10)\n",
    "    print(flow)\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    hsv[..., 0] = ang * 180 / np.pi / 2\n",
    "    hsv[..., 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    print('end of compute dense optical flow')\n",
    "    return cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_videos_to_tfrecord(source_path, destination_path,\n",
    "                               n_videos_in_record=10, n_frames_per_video='all',\n",
    "                               file_suffix=\"*.mp4\", dense_optical_flow=True,\n",
    "                               width=1280, height=720,\n",
    "                               color_depth=\"uint8\", video_filenames=None):\n",
    "    \"\"\"Starts the process of converting video files to tfrecord files. If\n",
    "    dense_optical_flow is set to True, the number of video channels in the\n",
    "    tfrecords will automatically 4, i.e. the pipeline assumes 3 (RGB) channels\n",
    "    in the videos. This pipeline does not (yet) support a different number of\n",
    "    channels.\n",
    "    Args:\n",
    "    source_path: directory where video videos are stored\n",
    "    destination_path: directory where tfrecords should be stored\n",
    "    n_videos_in_record: Number of videos stored in one single tfrecord file\n",
    "    n_frames_per_video: integer value of string. Specifies the number of frames extracted from each video. If set to 'all', all frames are extracted from the\n",
    "      videos and stored in the tfrecord. If the number is lower than the number of available frames, the subset of extracted frames will be selected equally\n",
    "      spaced over the entire video playtime.\n",
    "    file_suffix: defines the video file type, e.g. *.mp4\n",
    "      dense_optical_flow: boolean flag that controls if optical flow should be\n",
    "      used and added to tfrecords\n",
    "    width: the width of the videos in pixels\n",
    "    height: the height of the videos in pixels\n",
    "    color_depth: Color depth as string for the images stored in the tfrecord\n",
    "      files. Has to correspond to the source video color depth. Specified as\n",
    "      dtype (e.g. uint8 or uint16)\n",
    "    video_filenames: specify, if the the full paths to the videos can be\n",
    "      directly be provided. In this case, the source will be ignored.\n",
    "    \"\"\"\n",
    "    assert isinstance(n_frames_per_video, (int, str))\n",
    "\n",
    "    if type(n_frames_per_video) is str:\n",
    "        assert n_frames_per_video == \"all\"\n",
    "\n",
    "    if dense_optical_flow:\n",
    "        n_channels = 4\n",
    "    else:\n",
    "        n_channels = 3\n",
    "\n",
    "    if video_filenames is not None:\n",
    "        filenames = video_filenames\n",
    "    else:\n",
    "        filenames = gfile.Glob(os.path.join(source_path, file_suffix))\n",
    "    if not filenames:\n",
    "        raise RuntimeError('No data files found.')\n",
    "\n",
    "    print('Total videos found: ' + str(len(filenames)))\n",
    "\n",
    "    filenames_split = list(get_chunks(filenames, n_videos_in_record))\n",
    "\n",
    "    for i, batch in enumerate(filenames_split):\n",
    "        data = convert_video_to_numpy(filenames=batch, width=width, height=height,\n",
    "                                  n_frames_per_video=n_frames_per_video,\n",
    "                                  n_channels=n_channels,\n",
    "                                  dense_optical_flow=dense_optical_flow)\n",
    "        if n_videos_in_record > len(filenames):\n",
    "            total_batch_number = 1\n",
    "        else:\n",
    "            total_batch_number = int(math.ceil(len(filenames) / n_videos_in_record))\n",
    "        print('Batch ' + str(i + 1) + '/' + str(total_batch_number) + \" completed\")\n",
    "        assert data.size != 0, 'something went wrong during video to numpy conversion'\n",
    "\n",
    "    save_numpy_to_tfrecords(data, destination_path, 'batch_',\n",
    "                        n_videos_in_record, i + 1, total_batch_number,\n",
    "                        color_depth=color_depth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_video_to_numpy(filenames, n_frames_per_video, width, height,\n",
    "                           n_channels, dense_optical_flow=False):\n",
    "    \"\"\"Generates an ndarray from multiple video files given by filenames.\n",
    "    Implementation chooses frame step size automatically for a equal separation distribution of the video images.\n",
    "    Args:\n",
    "    filenames: a list containing the full paths to the video files\n",
    "    width: width of the video(s)\n",
    "    height: height of the video(s)\n",
    "    n_frames_per_video: integer value of string. Specifies the number of frames extracted from each video. If set to 'all', all frames are extracted from the\n",
    "    videos and stored in the tfrecord. If the number is lower than the number of available frames, the subset of extracted frames will be selected equally\n",
    "    spaced over the entire video playtime.\n",
    "    n_channels: number of channels to be used for the tfrecords\n",
    "    type: processing type for video data\n",
    "    Returns:\n",
    "    if no optical flow is used: ndarray(uint32) of shape (v,i,h,w,c) with\n",
    "    v=number of videos, i=number of images, (h,w)=height and width of image,\n",
    "    c=channel, if optical flow is used: ndarray(uint32) of (v,i,h,w,\n",
    "    c+1)\n",
    "    \"\"\"\n",
    "\n",
    "    number_of_videos = len(filenames)\n",
    "\n",
    "    if dense_optical_flow:\n",
    "    # need an additional channel for the optical flow with one exception:\n",
    "        n_channels = 4\n",
    "        num_real_image_channel = 3\n",
    "    else:\n",
    "        # if no optical flow, make everything normal:\n",
    "        num_real_image_channel = n_channels\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for i, file in enumerate(filenames):\n",
    "        try:\n",
    "            v = video_file_to_ndarray(i=i, file_path=file,\n",
    "                                n_frames_per_video=n_frames_per_video,\n",
    "                                height=height, width=width,\n",
    "                                n_channels=n_channels,\n",
    "                                num_real_image_channel=num_real_image_channel,\n",
    "                                dense_optical_flow=dense_optical_flow,\n",
    "                                number_of_videos=number_of_videos)\n",
    "            data.append(v)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_image_retrieval(cap, file_path, video, take_all_frames, steps, frame,\n",
    "                           prev_frame_none, frames_counter):\n",
    "    stop = False\n",
    "\n",
    "    if frame and prev_frame_none or steps <= 0:\n",
    "        stop = True\n",
    "        return stop, cap, video, steps, prev_frame_none, frames_counter\n",
    "\n",
    "    if not take_all_frames:\n",
    "        # repeat with smaller step size\n",
    "        steps -= 1\n",
    "\n",
    "    prev_frame_none = True\n",
    "    print(\"reducing step size due to error for video: \", file_path)\n",
    "    frames_counter = 0\n",
    "    cap.release()\n",
    "    cap = get_video_capture_and_frame_count(file_path)\n",
    "      # wait for image retrieval to be ready\n",
    "    time.sleep(2)\n",
    "    \n",
    "    return stop, cap, video, steps, prev_frame_none, frames_counter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_numpy_to_tfrecords(data, destination_path, name, fragmentSize,\n",
    "                            current_batch_number, total_batch_number,\n",
    "                            color_depth):\n",
    "    \"\"\"Converts an entire dataset into x tfrecords where x=videos/fragmentSize.\n",
    "        Args:\n",
    "        data: ndarray(uint32) of shape (v,i,h,w,c) with v=number of videos,\n",
    "        i=number of images, c=number of image channels, h=image height, w=image\n",
    "        width\n",
    "        name: filename; data samples type (train|valid|test)\n",
    "        fragmentSize: specifies how many videos are stored in one tfrecords file\n",
    "        current_batch_number: indicates the current batch index (function call within loop)\n",
    "        total_batch_number: indicates the total number of batches\n",
    "    \"\"\"\n",
    "\n",
    "    num_videos = data.shape[0]\n",
    "    num_images = data.shape[1]\n",
    "    num_channels = data.shape[4]\n",
    "    height = data.shape[2]\n",
    "    width = data.shape[3]\n",
    "\n",
    "    writer = None\n",
    "    feature = {}\n",
    "\n",
    "    for video_count in range((num_videos)):\n",
    "\n",
    "        if video_count % fragmentSize == 0:\n",
    "            if writer is not None:\n",
    "                writer.close()\n",
    "            filename = os.path.join(destination_path,name + str(current_batch_number) + '_of_' + str(\n",
    "                                total_batch_number) + '.tfrecords')\n",
    "            print('Writing', filename)\n",
    "            writer = tf.python_io.TFRecordWriter(filename)\n",
    "\n",
    "            for image_count in range(num_images):\n",
    "                path = 'blob' + '/' + str(image_count)\n",
    "                image = data[video_count, image_count, :, :, :]\n",
    "                image = image.astype(color_depth)\n",
    "                image_raw = image.tostring()\n",
    "\n",
    "                feature[path] = _bytes_feature(image_raw)\n",
    "                feature['height'] = _int64_feature(height)\n",
    "                feature['width'] = _int64_feature(width)\n",
    "                feature['depth'] = _int64_feature(num_channels)\n",
    "\n",
    "            example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "            writer.write(example.SerializeToString())\n",
    "    if writer is not None:\n",
    "        writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_file_to_ndarray(i, file_path, n_frames_per_video, height, width,\n",
    "                          n_channels, num_real_image_channel,\n",
    "                          dense_optical_flow, number_of_videos):\n",
    "    cap, frame_count = get_video_capture_and_frame_count(file_path)\n",
    "    print(frame_count)    \n",
    "    take_all_frames = False\n",
    "    # if not all frames are to be used, we have to skip some -> set step size accordingly\n",
    "    if n_frames_per_video == 'all':\n",
    "        take_all_frames = True\n",
    "        video = np.zeros((frame_count, height, width, n_channels), dtype=np.uint32)\n",
    "        steps = frame_count\n",
    "        n_frames = frame_count\n",
    "    else:\n",
    "        video = np.zeros((n_frames_per_video, height, width, n_channels),dtype=np.uint32)\n",
    "        steps = int(math.floor(frame_count / n_frames_per_video))\n",
    "        n_frames = n_frames_per_video\n",
    "    \n",
    "    assert not (frame_count < 1 or steps < 1), str(file_path) + \" does not have enough frames. Skipping video.\"\n",
    "    # variables needed\n",
    "    image = np.zeros((height, width, num_real_image_channel), dtype=FLAGS.image_color_depth)\n",
    "    frames_counter = 0\n",
    "    prev_frame_none = False\n",
    "    restart = True\n",
    "    image_prev = None\n",
    "    while restart:\n",
    "        for f in range(frame_count):\n",
    "            \n",
    "            if math.floor(f % steps) == 0 or take_all_frames:\n",
    "                frame = get_next_frame(cap)\n",
    "                \n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                # special case handling: opencv's frame count sometimes differs from real frame count -> repeat\n",
    "                if frame is None and frames_counter < n_frames:\n",
    "                    stop, cap, steps, prev_frame_none, frames_counter = repeat_image_retrieval(\n",
    "                            cap, file_path, take_all_frames, steps, frame, prev_frame_none,frames_counter)\n",
    "                    if stop:\n",
    "                        restart = False\n",
    "                        break\n",
    "                    else:\n",
    "                        video.fill(0)\n",
    "\n",
    "                else:\n",
    "                    if frames_counter >= n_frames:\n",
    "                        restart = False\n",
    "                        break\n",
    "\n",
    "                    # iterate over channels\n",
    "                    for k in range(num_real_image_channel):\n",
    "                        resizedImage = cv2.resize(frame[:, :, k], (width, height))\n",
    "                        image[:, :, k] = resizedImage\n",
    "\n",
    "                    if dense_optical_flow:\n",
    "                        # optical flow requires at least two images, make the OF image appended to the first image just black\n",
    "                        if image_prev is not None:\n",
    "                            \n",
    "                            frame_flow = compute_dense_optical_flow(image_prev, image)\n",
    "                            frame_flow = cv2.cvtColor(frame_flow, cv2.COLOR_BGR2GRAY)\n",
    "                        else:\n",
    "                            frame_flow = np.zeros((height, width))\n",
    "                        image_prev = image.copy()\n",
    "\n",
    "                    # assemble the video from the single images\n",
    "                    if dense_optical_flow:\n",
    "                        image_with_flow = image.copy()\n",
    "                        image_with_flow = np.concatenate((image_with_flow, np.expand_dims(frame_flow, axis=2)), axis=2)\n",
    "                        video[frames_counter, :, :, :] = image_with_flow\n",
    "                    else:\n",
    "                        video[frames_counter, :, :, :] = image\n",
    "                    frames_counter += 1\n",
    "            else:\n",
    "                get_next_frame(cap)\n",
    "\n",
    "    print(str(i + 1) + \" of \" + str(number_of_videos) + \" videos within batch processed: \", file_path)\n",
    "\n",
    "    v = video.copy()\n",
    "    cap.release()\n",
    "    return v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total videos found: 1\n",
      "1777\n",
      "[[[ -2.13185512e-03  -1.18888391e-03]\n",
      "  [ -5.50729828e-03  -1.89540014e-02]\n",
      "  [ -1.40104536e-02  -3.12390178e-02]\n",
      "  ..., \n",
      "  [  4.63453434e-05  -7.80481059e-05]\n",
      "  [ -1.99115875e-05  -2.23902607e-05]\n",
      "  [ -3.57265053e-05   1.03243738e-05]]\n",
      "\n",
      " [[ -4.65685129e-02  -1.17675392e-02]\n",
      "  [ -7.23999739e-02  -4.24565710e-02]\n",
      "  [ -1.73053250e-01  -6.38576001e-02]\n",
      "  ..., \n",
      "  [  2.32340190e-05  -7.40319374e-05]\n",
      "  [ -1.41818295e-04   2.64030878e-05]\n",
      "  [ -1.27070161e-04   6.16510515e-05]]\n",
      "\n",
      " [[ -1.18862599e-01  -2.45491712e-04]\n",
      "  [ -1.16981767e-01   9.95425135e-03]\n",
      "  [ -8.94871205e-02   4.83608022e-02]\n",
      "  ..., \n",
      "  [ -6.84321130e-05  -5.02746843e-05]\n",
      "  [ -2.90395517e-04   9.34337586e-05]\n",
      "  [ -2.13392661e-04   1.14316863e-04]]\n",
      "\n",
      " ..., \n",
      " [[  2.90611092e-06   2.55680770e-05]\n",
      "  [ -1.10241099e-05   7.55765068e-05]\n",
      "  [ -1.60700103e-04   3.73072944e-05]\n",
      "  ..., \n",
      "  [ -4.37008654e-04   2.54848594e-04]\n",
      "  [ -3.39585386e-04   1.52054345e-04]\n",
      "  [ -1.46197490e-04   4.48681458e-05]]\n",
      "\n",
      " [[  8.76733225e-07   6.51954224e-06]\n",
      "  [ -8.30773843e-06   2.21398950e-05]\n",
      "  [ -7.68195678e-05  -7.20374999e-07]\n",
      "  ..., \n",
      "  [ -2.16830304e-04   1.23214006e-04]\n",
      "  [ -1.79813374e-04   8.11272766e-05]\n",
      "  [ -7.96142558e-05   2.59937115e-05]]\n",
      "\n",
      " [[  2.24050680e-07   1.77356731e-06]\n",
      "  [ -3.37488177e-06   6.23293317e-06]\n",
      "  [ -2.41735979e-05  -2.02202818e-06]\n",
      "  ..., \n",
      "  [ -2.02765823e-05  -1.54651036e-06]\n",
      "  [ -2.58470045e-05   2.83984400e-06]\n",
      "  [ -1.35827950e-05   1.00957959e-06]]]\n",
      "end of compute dense optical flow\n",
      "[[[  8.70092332e-01  -2.71625519e-01]\n",
      "  [  7.43608427e+00  -1.87175071e+00]\n",
      "  [  2.04702911e+01  -4.74071503e+00]\n",
      "  ..., \n",
      "  [  3.76467433e-05   2.20354814e-05]\n",
      "  [ -9.31741056e-07   2.52186646e-06]\n",
      "  [ -3.53091809e-06   1.06419677e-07]]\n",
      "\n",
      " [[  8.48895741e+00  -3.02113223e+00]\n",
      "  [  2.99771252e+01  -1.05807171e+01]\n",
      "  [  5.29181480e+01  -1.84782066e+01]\n",
      "  ..., \n",
      "  [  7.43267956e-05   1.01429441e-05]\n",
      "  [ -1.96312576e-05  -9.66668722e-06]\n",
      "  [ -9.96994913e-06  -4.39000905e-06]]\n",
      "\n",
      " [[  2.63457985e+01  -8.19877720e+00]\n",
      "  [  6.05193214e+01  -2.00212631e+01]\n",
      "  [  8.07114563e+01  -2.78496532e+01]\n",
      "  ..., \n",
      "  [  1.92170592e-05  -6.99953807e-06]\n",
      "  [ -6.51191513e-05  -2.41108082e-05]\n",
      "  [ -1.72475520e-05  -8.35216633e-06]]\n",
      "\n",
      " ..., \n",
      " [[  1.38649053e-03  -4.49967124e-02]\n",
      "  [  1.28669247e-01  -6.51286781e-01]\n",
      "  [  1.33537149e+00  -3.59645724e+00]\n",
      "  ..., \n",
      "  [  1.12326352e-05  -9.61542082e-06]\n",
      "  [  1.24260687e-05  -8.76933336e-06]\n",
      "  [  6.41352472e-06  -2.91630499e-06]]\n",
      "\n",
      " [[  5.37054730e-04  -2.23129839e-02]\n",
      "  [  3.05855535e-02  -3.16332281e-01]\n",
      "  [  3.27418149e-01  -9.76115227e-01]\n",
      "  ..., \n",
      "  [  2.68176314e-06  -1.37097106e-06]\n",
      "  [  3.51495305e-06  -1.29292800e-06]\n",
      "  [  1.86261900e-06  -3.28420015e-07]]\n",
      "\n",
      " [[  4.26568033e-04  -1.18049271e-02]\n",
      "  [  7.74979359e-04  -1.79451331e-02]\n",
      "  [  1.17527777e-02  -1.91769525e-01]\n",
      "  ..., \n",
      "  [  6.79166760e-07   6.34408764e-07]\n",
      "  [  6.22637970e-07   5.21624429e-07]\n",
      "  [  1.77806257e-07   2.06685840e-07]]]\n",
      "end of compute dense optical flow\n",
      "[[[  3.93863386e-09  -1.11144978e-08]\n",
      "  [  2.13878817e-08  -1.94286631e-08]\n",
      "  [  3.96427566e-08   7.90940113e-09]\n",
      "  ..., \n",
      "  [  1.75858010e-03  -2.83323252e-03]\n",
      "  [  2.56155059e-03  -6.73796865e-04]\n",
      "  [  1.64472044e-03   2.61718324e-05]]\n",
      "\n",
      " [[  6.90886282e-08   6.59226842e-08]\n",
      "  [  2.65670764e-07   1.85778632e-07]\n",
      "  [  7.78785989e-07   1.23843836e-06]\n",
      "  ..., \n",
      "  [  1.34340758e-02   2.27130596e-02]\n",
      "  [  1.09157562e-02   2.83709005e-03]\n",
      "  [  5.74070681e-03   9.08562448e-04]]\n",
      "\n",
      " [[  1.78590142e-07   1.40614432e-07]\n",
      "  [  6.81649965e-07   3.97149165e-07]\n",
      "  [  2.06066443e-06   2.78142079e-06]\n",
      "  ..., \n",
      "  [  2.43314449e-02   4.09623608e-02]\n",
      "  [  1.61667243e-02   4.90657939e-03]\n",
      "  [  8.53304006e-03   1.83787092e-03]]\n",
      "\n",
      " ..., \n",
      " [[ -5.70676439e-02   6.33153975e-01]\n",
      "  [ -1.57543689e-01   1.11941183e+00]\n",
      "  [ -1.96154594e-01   9.06128407e-01]\n",
      "  ..., \n",
      "  [  2.26776741e-04   2.74076228e-05]\n",
      "  [  9.68024906e-05   1.44644146e-05]\n",
      "  [  1.90837163e-05   8.09051357e-07]]\n",
      "\n",
      " [[ -3.01378593e-02   2.84466326e-01]\n",
      "  [ -8.37578401e-02   5.48639894e-01]\n",
      "  [ -1.03021450e-01   4.59000707e-01]\n",
      "  ..., \n",
      "  [  1.28604923e-04  -4.56731277e-06]\n",
      "  [  5.77659193e-05   2.17238387e-08]\n",
      "  [  1.13130545e-05  -1.83955979e-06]]\n",
      "\n",
      " [[ -9.57422331e-03   6.41620457e-02]\n",
      "  [ -2.90790256e-02   1.48470923e-01]\n",
      "  [ -3.55957523e-02   1.29331142e-01]\n",
      "  ..., \n",
      "  [  4.34947324e-05  -6.60344858e-06]\n",
      "  [  2.01278799e-05  -2.32840853e-06]\n",
      "  [  3.60952686e-06  -1.62613912e-06]]]\n",
      "end of compute dense optical flow\n",
      "[[[ -3.69753153e-08   7.80940379e-09]\n",
      "  [ -1.20237909e-08  -2.10644870e-08]\n",
      "  [  2.74729501e-07  -5.15413490e-07]\n",
      "  ..., \n",
      "  [  1.02622490e-02   1.77729920e-01]\n",
      "  [  2.42521847e-03   2.35586036e-02]\n",
      "  [ -4.34268790e-04   2.11244551e-04]]\n",
      "\n",
      " [[ -1.19984364e-07  -4.65399133e-08]\n",
      "  [ -1.98214991e-07  -1.09799153e-07]\n",
      "  [  2.12535633e-06   1.26472241e-05]\n",
      "  ..., \n",
      "  [  8.98946524e-02   8.81875277e-01]\n",
      "  [  3.46225165e-02   1.56451330e-01]\n",
      "  [ -1.23479241e-03   3.17485700e-03]]\n",
      "\n",
      " [[ -2.36085867e-07  -1.09244340e-07]\n",
      "  [ -8.75170542e-07  -1.14711929e-09]\n",
      "  [  1.48209256e-06   3.15770449e-05]\n",
      "  ..., \n",
      "  [  2.34705418e-01   1.92743456e+00]\n",
      "  [  1.00459777e-01   4.81806725e-01]\n",
      "  [ -1.75721233e-03   6.34209672e-03]]\n",
      "\n",
      " ..., \n",
      " [[  9.42540937e-04  -5.29495068e-03]\n",
      "  [  5.43986447e-02  -1.31921202e-01]\n",
      "  [  2.36601502e-01  -5.59273064e-01]\n",
      "  ..., \n",
      "  [ -1.03476492e-03  -1.40177173e-04]\n",
      "  [ -4.81591618e-04  -1.16094619e-04]\n",
      "  [ -8.45276954e-05  -2.82355541e-05]]\n",
      "\n",
      " [[  1.72938081e-03  -2.13141460e-03]\n",
      "  [  3.90307978e-02  -7.79079869e-02]\n",
      "  [  1.41358554e-01  -3.18169892e-01]\n",
      "  ..., \n",
      "  [ -4.04317252e-04  -7.04176418e-05]\n",
      "  [ -1.99374030e-04  -4.84756456e-05]\n",
      "  [ -3.63126455e-05  -6.07183256e-06]]\n",
      "\n",
      " [[  5.93621924e-04  -6.72771595e-04]\n",
      "  [  1.34633435e-02  -2.84251925e-02]\n",
      "  [  4.56484109e-02  -1.15067795e-01]\n",
      "  ..., \n",
      "  [ -1.00340068e-04  -2.82209476e-06]\n",
      "  [ -5.03062329e-05   5.99777150e-06]\n",
      "  [ -1.08772329e-05   7.11512303e-06]]]\n",
      "end of compute dense optical flow\n",
      "1 of 1 videos within batch processed:  ../OpenCV/IMG_0612.MOV\n",
      "Batch 1/1 completed\n",
      "Writing ./data/batch_1_of_1.tfrecords\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    num_depth = 4\n",
    "    in_path = \"../OpenCV/\"\n",
    "    out_path = \"./data\"\n",
    "    n_frames = 5\n",
    "\n",
    "    try:\n",
    "        if not os.path.exists('data'):\n",
    "            os.makedirs('data')\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory of data')\n",
    "    convert_videos_to_tfrecord(source_path=in_path, destination_path=out_path,\n",
    "                                   n_videos_in_record=10,\n",
    "                                   n_frames_per_video=n_frames,\n",
    "                                   dense_optical_flow=True,\n",
    "                                   file_suffix=\"*.MOV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ComputerVision]",
   "language": "python",
   "name": "conda-env-ComputerVision-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
